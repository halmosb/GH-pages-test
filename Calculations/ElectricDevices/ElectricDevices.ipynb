{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MzqvGZbz0Hc"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Datacompintensive/LLFT/blob/master/Notebooks/Coffee2/Coffee.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2G82qwXOz0Hd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOowcGkz0He",
        "outputId": "1b712d01-bdf3-4bfe-913c-531c2bfcabef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google colab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "print(f'Running on {\"Google colab\" if IN_COLAB else \"Local computer\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIqMEKikz0He",
        "outputId": "81dbfd63-773a-4406-bfac-84aef787d13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m862.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n",
            "Collecting aeon\n",
            "  Downloading aeon-0.9.0-py3-none-any.whl (54.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba<0.60.0,>=0.55 in /usr/local/lib/python3.10/dist-packages (from aeon) (0.58.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (24.1)\n",
            "Requirement already satisfied: pandas<2.1.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from aeon) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn<1.5.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.2.2)\n",
            "Requirement already satisfied: scipy<1.13.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (4.12.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.60.0,>=0.55->aeon) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=1.0.0->aeon) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=1.0.0->aeon) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.1.0,>=1.5.3->aeon) (1.16.0)\n",
            "Installing collected packages: deprecated, aeon\n",
            "Successfully installed aeon-0.9.0 deprecated-1.2.14\n",
            "--2024-06-12 20:18:08--  https://raw.githubusercontent.com/Datacompintensive/LLFT/master/src/LLFT.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14093 (14K) [text/plain]\n",
            "Saving to: ‘LLFT.py’\n",
            "\n",
            "LLFT.py             100%[===================>]  13.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-12 20:18:08 (71.0 MB/s) - ‘LLFT.py’ saved [14093/14093]\n",
            "\n",
            "--2024-06-12 20:18:08--  https://raw.githubusercontent.com/Datacompintensive/LLFT/master/src/ClassificationLearner.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11863 (12K) [text/plain]\n",
            "Saving to: ‘ClassificationLearner.py’\n",
            "\n",
            "ClassificationLearn 100%[===================>]  11.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-12 20:18:08 (92.6 MB/s) - ‘ClassificationLearner.py’ saved [11863/11863]\n",
            "\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/Research/Wigner/TimeSeries\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install scikit-optimize\n",
        "    !pip install aeon\n",
        "    try:\n",
        "        !rm -rf LLFT.py\n",
        "        !rm -rf ClassificationLearner.py\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    !wget https://raw.githubusercontent.com/Datacompintensive/LLFT/master/src/LLFT.py\n",
        "    !wget https://raw.githubusercontent.com/Datacompintensive/LLFT/master/src/ClassificationLearner.py\n",
        "    from LLFT import *\n",
        "    from ClassificationLearner import *\n",
        "    drive.mount('/content/drive/')\n",
        "    #Overwrite path\n",
        "    %cd /content/drive/My Drive/Research/Wigner/TimeSeries\n",
        "else:\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # Driver magic\n",
        "    import sys\n",
        "    sys.path.insert(0, \"../../src\")\n",
        "    from LLFT import *\n",
        "    from ClassificationLearner import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cqayN3RBz0He"
      },
      "outputs": [],
      "source": [
        "database = \"ElectricDevices\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2A-VZqB0Ech",
        "outputId": "df0455e8-7d22-4e1d-f1be-3dbdf111e99a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "slMmjrOz3J3x"
      },
      "outputs": [],
      "source": [
        "seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olIckIknz0Hf",
        "outputId": "0b45e4d3-e0e7-48f8-c8f9-14387812a425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set shape: torch.Size([4463, 96])\n",
            "train classes: (tensor([1, 2, 3, 4, 5, 6, 7], dtype=torch.int8), tensor([ 361, 1101,  447,  713, 1193,  269,  379]))\n",
            "\n",
            "c_train_set shape: torch.Size([4463, 96])\n",
            "c train classes: (tensor([1, 2, 3, 4, 5, 6, 7], dtype=torch.int8), tensor([ 366, 1130,  404,  761, 1213,  240,  349]))\n",
            "\n",
            "test_set shape: torch.Size([7711, 96])\n",
            "test classes: (tensor([1, 2, 3, 4, 5, 6, 7], dtype=torch.int8), tensor([ 667, 1956,  755, 1165, 1869,  743,  556]))\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from aeon.datasets import load_classification\n",
        "    X, y = load_classification(database)\n",
        "    y = y.astype(np.int8)\n",
        "    #CHANGE HERE!\n",
        "    train_set, test_set = X[:28], X[28:]\n",
        "    train_classes, test_classes = y[:28], y[28:]\n",
        "else:\n",
        "    dbpath = f\"../../databases/{database}/\"\n",
        "\n",
        "    X = pd.read_csv(f\"{dbpath}{database}_TEST\", header=None).values\n",
        "    test_classes = X[:,0]\n",
        "    test_set = X[:,1:]\n",
        "\n",
        "    X = pd.read_csv(f\"{dbpath}{database}_TRAIN\", header=None).values\n",
        "    train_classes = X[:,0]\n",
        "    train_set = X[:,1:]\n",
        "\n",
        "test_classes = torch.tensor(test_classes, dtype=torch.int8)\n",
        "test_set = torch.tensor(test_set, dtype=torch.float32)\n",
        "train_classes = torch.tensor(train_classes, dtype=torch.int8)\n",
        "train_set = torch.tensor(train_set, dtype=torch.float32)\n",
        "\n",
        "train_set, c_train_set, train_classes, c_train_classes = train_test_split(train_set, train_classes, train_size=0.5, random_state=seed)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"train_set shape: {train_set.shape}\")\n",
        "print(\"train classes:\", train_classes.unique(return_counts=True))\n",
        "print()\n",
        "print(f\"c_train_set shape: {c_train_set.shape}\")\n",
        "print(\"c train classes:\", c_train_classes.unique(return_counts=True))\n",
        "print()\n",
        "print(f\"test_set shape: {test_set.shape}\")\n",
        "print(\"test classes:\", test_classes.unique(return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jve33hsnq3j_",
        "outputId": "21534e1e-c20b-47ae-b4fe-7feb917dc7cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.shape[-1] / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjaJHCQN4_82"
      },
      "outputs": [],
      "source": [
        "L = [20]\n",
        "k = 1\n",
        "\n",
        "llft = LLFT(train_set, train_classes, L=L, k=k, device=device)\n",
        "llft.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P5kufqTt5rWz"
      },
      "outputs": [],
      "source": [
        "extr_methods = {ExtractMethods.mean : {}, ExtractMethods.var : {}}\n",
        "c_train_filename = f\"{database}_c_features.csv\"\n",
        "test_filename = f\"{database}_test_features.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "YGinRrgi6Ury",
        "outputId": "81df1590-4871-4c86-c58c-e041c7e68b86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transformed_test_set = llft.collect_features(test_set, extr_methods=extr_methods, test_classes=test_classes,\\\n",
        "                                             save_file_name=test_filename, save_file_mode=\"Append feature\")\n",
        "display(transformed_test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "puJTcBYX7DpZ",
        "outputId": "fd238539-783c-4630-c984-8bf25f7be04d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transformed_c_train_set = llft.collect_features(c_train_set, extr_methods=extr_methods, test_classes=c_train_classes,\\\n",
        "                                                save_file_name=c_train_filename, save_file_mode=\"Append feature\")\n",
        "display(transformed_c_train_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjnRf-rW82_E",
        "outputId": "47b403df-dbbf-4b15-a75a-dd1b67e27b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 8\n",
            "Error: linalg.eigh: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated eigenvalues (error code: 1).\n",
            "L: 12\n",
            "Error: linalg.eigh: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated eigenvalues (error code: 1).\n",
            "L: 25\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 30\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 35\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 45\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L: 48\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([7711, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4463, 14])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "L_vals = [8, 12, 25, 30, 35, 40, 45, 48]\n",
        "for L in L_vals:\n",
        "    try:\n",
        "        print(f\"L: {L}\")\n",
        "        k = 1\n",
        "\n",
        "        llft = LLFT(train_set, train_classes, L=L, k=k, device=device)\n",
        "        llft.train()\n",
        "        transformed_test_set = llft.collect_features(test_set, extr_methods=extr_methods, test_classes=test_classes,\\\n",
        "                                                save_file_name=test_filename, save_file_mode=\"Append feature\")\n",
        "        display(transformed_test_set.shape)\n",
        "        transformed_c_train_set = llft.collect_features(c_train_set, extr_methods=extr_methods, test_classes=c_train_classes,\\\n",
        "                                                    save_file_name=c_train_filename, save_file_mode=\"Append feature\")\n",
        "        display(transformed_c_train_set.shape)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga2vJbH0q3kB",
        "outputId": "f3c65bb9-637f-4583-d8de-746e63662f35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4463, 127)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(7711, 127)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(pd.read_csv(c_train_filename).values.shape)\n",
        "display(pd.read_csv(test_filename).values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qiweuVi7q3kC",
        "outputId": "196cbabe-dabd-4fdd-f1ce-c2c5eaa89370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (4016, 126)\n",
            "Train classes: (array([1., 2., 3., 4., 5., 6., 7.]), array([ 337, 1004,  365,  703, 1090,  215,  302]))\n",
            "\n",
            "X_validation shape: (447, 126)\n",
            "Validation classes: (array([1., 2., 3., 4., 5., 6., 7.]), array([ 29, 126,  39,  58, 123,  25,  47]))\n",
            "\n",
            "opt-knn optimization; validation:\n",
            "Method: opt-knn\n",
            "Accuracy: 0.69575\n",
            "Confusion Matrix:\n",
            "[[ 23   0   1   4   0   1   0]\n",
            " [  0 120   0   1   5   0   0]\n",
            " [  0   0  28   3   2   0   6]\n",
            " [  7   0   6  29   9   6   1]\n",
            " [  3   7   3  10  94   2   4]\n",
            " [  7   0   1   8   0   9   0]\n",
            " [  4   1  18   3  12   1   8]]\n",
            "\n",
            "\n",
            "Method: def-knn\n",
            "Accuracy: 0.56932\n",
            "Confusion Matrix:\n",
            "[[ 249    0   13  179  160   64    2]\n",
            " [   6 1448   38  205  255    0    4]\n",
            " [  27    0  556   41   14    9  108]\n",
            " [ 159    7  129  616  143   74   37]\n",
            " [  58  218   47  150 1356    6   34]\n",
            " [ 219    0   23  323   25  149    4]\n",
            " [   8  109    8   70  345    0   16]]\n",
            "\n",
            "Method: def-svm\n",
            "Accuracy: 0.55518\n",
            "Confusion Matrix:\n",
            "[[ 205  145   36  266   15    0    0]\n",
            " [   3 1753   32   14  154    0    0]\n",
            " [  25    2  560  168    0    0    0]\n",
            " [ 106    1  311  538  209    0    0]\n",
            " [  16  484   48   96 1225    0    0]\n",
            " [ 225    0   69  411   38    0    0]\n",
            " [   2   24    7   16  507    0    0]]\n",
            "\n",
            "Method: def-rf\n",
            "Accuracy: 0.68227\n",
            "Confusion Matrix:\n",
            "[[ 267    0    4  156  180   53    7]\n",
            " [   0 1577    0   81  293    0    5]\n",
            " [  14    0  593   38    5   12   93]\n",
            " [ 123    0  110  725  133   44   30]\n",
            " [   8   55   17   88 1671    2   28]\n",
            " [  55    0   13  234   32  401    8]\n",
            " [   3   45    2   39  439    1   27]]\n",
            "\n",
            "Method: def-dt\n",
            "Accuracy: 0.59953\n",
            "Confusion Matrix:\n",
            "[[ 239    1   22  140  178   80    7]\n",
            " [   0 1454    2  113  351    1   35]\n",
            " [  18   10  489   43   22   22  151]\n",
            " [ 143    1  108  607  168   91   47]\n",
            " [  23  152   62  122 1391    9  110]\n",
            " [  70    0   18  257   47  327   24]\n",
            " [   5   92   11   79  239   14  116]]\n",
            "\n",
            "Method: opt-knn\n",
            "Accuracy: 0.59058\n",
            "Confusion Matrix:\n",
            "[[ 227    0    9  182  157   87    5]\n",
            " [   6 1536   35   99  274    2    4]\n",
            " [  29    0  590   29    8   15   84]\n",
            " [ 104    6  119  624  155  100   57]\n",
            " [  31  223   39  154 1386    6   30]\n",
            " [ 164    0   17  338   29  181   14]\n",
            " [   7  104    9   52  374    0   10]]\n",
            "\n",
            "Classifier opt-svm is not trained!\n",
            "\n",
            "Classifier opt-rf is not trained!\n",
            "\n",
            "Classifier opt-dt is not trained!\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[0.6822720788483984,\n",
              "  'def-rf',\n",
              "  {'bootstrap': True,\n",
              "   'ccp_alpha': 0.0,\n",
              "   'class_weight': None,\n",
              "   'criterion': 'gini',\n",
              "   'max_depth': None,\n",
              "   'max_features': 'sqrt',\n",
              "   'max_leaf_nodes': None,\n",
              "   'max_samples': None,\n",
              "   'min_impurity_decrease': 0.0,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'min_weight_fraction_leaf': 0.0,\n",
              "   'n_estimators': 100,\n",
              "   'n_jobs': None,\n",
              "   'oob_score': False,\n",
              "   'random_state': None,\n",
              "   'verbose': 0,\n",
              "   'warm_start': False}],\n",
              " [0.5995331344832058,\n",
              "  'def-dt',\n",
              "  {'ccp_alpha': 0.0,\n",
              "   'class_weight': None,\n",
              "   'criterion': 'gini',\n",
              "   'max_depth': None,\n",
              "   'max_features': None,\n",
              "   'max_leaf_nodes': None,\n",
              "   'min_impurity_decrease': 0.0,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'min_weight_fraction_leaf': 0.0,\n",
              "   'random_state': None,\n",
              "   'splitter': 'best'}],\n",
              " [0.5905848787446505,\n",
              "  'opt-knn',\n",
              "  {'algorithm': 'ball_tree',\n",
              "   'leaf_size': 30,\n",
              "   'metric': 'manhattan',\n",
              "   'metric_params': None,\n",
              "   'n_jobs': None,\n",
              "   'n_neighbors': 9,\n",
              "   'p': 2,\n",
              "   'weights': 'distance'}],\n",
              " [0.5693165607573596,\n",
              "  'def-knn',\n",
              "  {'algorithm': 'auto',\n",
              "   'leaf_size': 30,\n",
              "   'metric': 'minkowski',\n",
              "   'metric_params': None,\n",
              "   'n_jobs': None,\n",
              "   'n_neighbors': 5,\n",
              "   'p': 2,\n",
              "   'weights': 'uniform'}],\n",
              " [0.5551809103877577,\n",
              "  'def-svm',\n",
              "  {'C': 1.0,\n",
              "   'break_ties': False,\n",
              "   'cache_size': 200,\n",
              "   'class_weight': None,\n",
              "   'coef0': 0.0,\n",
              "   'decision_function_shape': 'ovr',\n",
              "   'degree': 3,\n",
              "   'gamma': 'scale',\n",
              "   'kernel': 'rbf',\n",
              "   'max_iter': -1,\n",
              "   'probability': False,\n",
              "   'random_state': None,\n",
              "   'shrinking': True,\n",
              "   'tol': 0.001,\n",
              "   'verbose': False}]]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "used_classes = None\n",
        "verbose=True\n",
        "cl = ClassificationLearner(transformed_c_train_set, transformed_c_train_classes, used_classes=used_classes, validation_size=0.1, verbose=verbose, random_state=0)\n",
        "cl.train([\"opt-knn\"], bayes_settings={\"n_iter\": 10}, verbose=verbose)\n",
        "cl.test([\"all\"], transformed_test_set, transformed_test_classes, verbose=verbose)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "\n",
        "class HyperparameterOptimizer:\n",
        "    def __init__(self, c_train_filename, test_filename, verbose=True, random_state=0):\n",
        "        self.verbose = verbose\n",
        "        self.random_state = random_state\n",
        "        np.random.seed(random_state)\n",
        "        transformed_c_train_data = pd.read_csv(c_train_filename).values\n",
        "        self.transformed_c_train_set, self.transformed_c_train_classes = transformed_c_train_data[:, :-1], transformed_c_train_data[:, -1]\n",
        "\n",
        "        transformed_test_data = pd.read_csv(test_filename).values\n",
        "        self.transformed_test_set, self.transformed_test_classes = transformed_test_data[:, :-1], transformed_test_data[:, -1]\n",
        "\n",
        "        self.headers = list(pd.read_csv(c_train_filename))\n",
        "        self.L_array, self.C_array, self.F_array, self.m_array = self.extract_and_process_parts(self.headers[:-1])\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Headers: {self.headers[:5]}..., length: {len(self.headers)}\")\n",
        "            print(f\"L: {self.L_array}, C: {self.C_array}, F: {self.F_array}, m: {self.m_array}\")\n",
        "            print()\n",
        "            print(f\"transformed_c_train_set.shape: {self.transformed_c_train_set.shape}\")\n",
        "            print(f\"transformed_c_train_classes: {np.unique(self.transformed_c_train_classes, return_counts=True)}\")\n",
        "            print()\n",
        "            print(f\"transformed_test_set.shape: {self.transformed_test_set.shape}\")\n",
        "            print(f\"transformed_test_classes: {np.unique(self.transformed_test_classes, return_counts=True)}\")\n",
        "\n",
        "\n",
        "    def extract_and_process_parts(self, items):\n",
        "        # Extract parts and convert them to integers where applicable\n",
        "        L_values, C_values, F_values, m_values = zip(*[(int(L[1:]), int(C[1:]), F[1:], int(m[1:])) for L, C, F, m in (item.split('-') for item in items)])\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        L_array = np.unique(np.array(L_values))\n",
        "        C_array = np.unique(np.array(C_values))\n",
        "        F_array = list(np.unique(np.array(F_values)))\n",
        "        m_array = np.unique(np.array(m_values))\n",
        "\n",
        "        return L_array, C_array, F_array, m_array\n",
        "\n",
        "\n",
        "    def find_indices(self, main_list, subset_list):\n",
        "        \"\"\"\n",
        "        Finds the indices of the elements of subset_list within main_list.\n",
        "\n",
        "        Parameters:\n",
        "        main_list (list): The main list containing all elements.\n",
        "        subset_list (list): The subset list whose indices in the main list are to be found.\n",
        "\n",
        "        Returns:\n",
        "        list: A list of indices corresponding to the positions of subset_list elements in main_list.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check for non-unique values in the main_list\n",
        "        seen = set()\n",
        "        duplicates = set()\n",
        "        for element in main_list:\n",
        "            if element in seen:\n",
        "                duplicates.add(element)\n",
        "            else:\n",
        "                seen.add(element)\n",
        "        if duplicates:\n",
        "            print(f\"Error: Non-unique values found in main_list: {duplicates}\")\n",
        "\n",
        "        indices = []\n",
        "        for element in subset_list:\n",
        "            try:\n",
        "                index = main_list.index(element)\n",
        "                indices.append(index)\n",
        "            except ValueError:\n",
        "                print(f\"Element {element} not found in main_list.\")\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def get_headers(self, L=None, C=None, F=None, m=None, return_indices=True):\n",
        "\n",
        "        if L and type(L) is not list:\n",
        "            L = [L]\n",
        "        if C and type(C) is not list:\n",
        "            C = [C]\n",
        "        if F and type(F) is not list:\n",
        "            F = [F]\n",
        "        if m and type(m) is not list:\n",
        "            m = [m]\n",
        "\n",
        "        ret = self.headers[:]\n",
        "        if L:\n",
        "            tmp = []\n",
        "            for l in L:\n",
        "                tmp += [x for x in ret if f\"L{l}-\" in x]\n",
        "            ret = tmp[:]\n",
        "        if C:\n",
        "            tmp = []\n",
        "            for c in C:\n",
        "                tmp += [x for x in ret if f\"C{c}-\" in x]\n",
        "            ret = tmp[:]\n",
        "        if F:\n",
        "            tmp = []\n",
        "            for f in F:\n",
        "                tmp += [x for x in ret if f\"F{f}-\" in x]\n",
        "            ret = tmp[:]\n",
        "        if m:\n",
        "            tmp = []\n",
        "            for M in m:\n",
        "                tmp += [x for x in ret if f\"m{M}\" in x]\n",
        "            ret = tmp[:]\n",
        "\n",
        "        if return_indices:\n",
        "            ret = self.find_indices(self.headers, ret)\n",
        "        return ret\n",
        "\n",
        "    def objective_function(self, subset_L, subset_F):\n",
        "        cl = self.create_cl_object(subset_L, subset_F)\n",
        "        ret = cl.test([\"all\"], self.transformed_test_set, self.transformed_test_classes, verbose=False)\n",
        "        #ret = cl.train([\"all-def\"], verbose=False)\n",
        "        if self.verbose:\n",
        "            print(f\"L: {subset_L}, F: {subset_F}, accuracy: {ret[0][0:2]}\")\n",
        "        return ret[0][0]\n",
        "\n",
        "    def bayesian_optimization(self, n_iterations=20):\n",
        "        list1, list2 = self.L_array, self.F_array\n",
        "        def wrapped_objective(params):\n",
        "            subset_indices1 = params[:len(list1)]\n",
        "            subset_indices2 = params[len(list1):]\n",
        "\n",
        "            subset1 = [list1[i] for i in range(len(list1)) if subset_indices1[i]]\n",
        "            subset2 = [list2[i] for i in range(len(list2)) if subset_indices2[i]]\n",
        "\n",
        "            return -self.objective_function(subset1, subset2)  # We negate because we want to maximize\n",
        "\n",
        "        dimensions = [Categorical([0, 1]) for _ in range(len(list1) + len(list2))]\n",
        "\n",
        "        result = gp_minimize(wrapped_objective, dimensions, n_calls=n_iterations, random_state=self.random_state)\n",
        "\n",
        "        best_indices = result.x\n",
        "        best_subset1 = [list1[i] for i in range(len(list1)) if best_indices[i]]\n",
        "        best_subset2 = [list2[i] for i in range(len(list2)) if best_indices[len(list1) + i]]\n",
        "\n",
        "        cl = self.create_cl_object(best_subset1, best_subset2, False)\n",
        "        cl_test = cl.test([\"all\"], self.transformed_test_set, self.transformed_test_classes, verbose=True)\n",
        "        return best_subset1, best_subset2, -result.fun, cl_test\n",
        "\n",
        "    def random_search(self, n_iterations=20):\n",
        "        list1, list2 = self.L_array, self.F_array\n",
        "        best_value = -float('inf')\n",
        "        best_subset1 = []\n",
        "        best_subset2 = []\n",
        "\n",
        "        for _ in range(n_iterations):\n",
        "            subset1 = [list1[i] for i in range(len(list1)) if np.random.choice([True, False])]\n",
        "            subset2 = [list2[i] for i in range(len(list2)) if np.random.choice([True, False])]\n",
        "\n",
        "            if subset1 and subset2:\n",
        "                value = self.objective_function(subset1, subset2)\n",
        "                if value > best_value:\n",
        "                    best_value = value\n",
        "                    best_subset1 = subset1\n",
        "                    best_subset2 = subset2\n",
        "\n",
        "        cl = self.create_cl_object(best_subset1, best_subset2, False)\n",
        "        cl_test = cl.test([\"all\"], self.transformed_test_set, self.transformed_test_classes, verbose=True)\n",
        "        return best_subset1, best_subset2, best_value, cl_test\n",
        "\n",
        "    def create_cl_object(self, subset_L, subset_F, verbose=False):\n",
        "        used_classes = self.get_headers(L=subset_L, F=subset_F, return_indices=True)\n",
        "        cl = ClassificationLearner(self.transformed_c_train_set, self.transformed_c_train_classes, used_classes=used_classes, validation_size=0.1, verbose=verbose, random_state=self.random_state)\n",
        "        #cl.train([\"opt-knn\"], bayes_settings={\"n_iter\": 10}, verbose=False)\n",
        "        return cl\n",
        "\n",
        "c_train_filename = f\"Data/{database}_c_features.csv\"\n",
        "test_filename = f\"Data/{database}_test_features.csv\"\n",
        "\n",
        "ho = HyperparameterOptimizer(c_train_filename, test_filename, True)\n",
        "\n",
        "print(\"\\nRandom Search:\")\n",
        "# Random Search\n",
        "best_subset1_rs, best_subset2_rs, best_value_rs, cl_test = ho.random_search(n_iterations=3)\n",
        "print(\"Best Subset 1:\", best_subset1_rs)\n",
        "print(\"Best Subset 2:\", best_subset2_rs)\n",
        "print(\"Best Objective Value:\", best_value_rs)\n",
        "print(\"Cl test\", cl_test[0][0:2])\n",
        "\n",
        "print()\n",
        "print(\"Bayesian Optimization:\")\n",
        "# Bayesian Optimization\n",
        "best_subset1_bo, best_subset2_bo, best_value_bo, cl_test = ho.bayesian_optimization(n_iterations=10)\n",
        "print(\"Best Subset 1:\", best_subset1_bo)\n",
        "print(\"Best Subset 2:\", best_subset2_bo)\n",
        "print(\"Best Objective Value:\", best_value_bo)\n",
        "print(\"Cl test\", cl_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUp9i18CsBvI",
        "outputId": "ea90306a-acd8-4ea5-8527-76c899e40a25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers: ['L2-C0-Fmean-m0', 'L2-C0-Fvar-m0', 'L2-C1-Fmean-m0', 'L2-C1-Fvar-m0', 'L2-C2-Fmean-m0']..., length: 127\n",
            "L: [ 2  5 20 25 30 35 40 45 48], C: [0 1 2 3 4 5 6], F: ['mean', 'var'], m: [0]\n",
            "\n",
            "transformed_c_train_set.shape: (4463, 126)\n",
            "transformed_c_train_classes: (array([1., 2., 3., 4., 5., 6., 7.]), array([ 366, 1130,  404,  761, 1213,  240,  349]))\n",
            "\n",
            "transformed_test_set.shape: (7711, 126)\n",
            "transformed_test_classes: (array([1., 2., 3., 4., 5., 6., 7.]), array([ 667, 1956,  755, 1165, 1869,  743,  556]))\n",
            "\n",
            "Random Search:\n",
            "L: [2, 5, 25, 30, 35, 40, 45], F: ['mean'], accuracy: [0.6744909869018285, 'def-rf']\n",
            "L: [5, 40], F: ['mean', 'var'], accuracy: [0.6372714304240695, 'def-rf']\n",
            "Method: def-knn\n",
            "Accuracy: 0.56011\n",
            "Confusion Matrix:\n",
            "[[ 235    3    6  159  163  101    0]\n",
            " [   1 1360   20  153  421    1    0]\n",
            " [  10    4  552   46   15   12  116]\n",
            " [ 143    3  140  600  155  101   23]\n",
            " [  26  274   32  180 1334    4   19]\n",
            " [ 154    1   12  321   37  217    1]\n",
            " [   0  199    6   40  289    1   21]]\n",
            "\n",
            "Method: def-svm\n",
            "Accuracy: 0.60433\n",
            "Confusion Matrix:\n",
            "[[ 221   13    9  281  143    0    0]\n",
            " [   0 1628   11   45  272    0    0]\n",
            " [   6    4  672   72    0    1    0]\n",
            " [  43    3  205  742  165    7    0]\n",
            " [  10  257   41  176 1384    1    0]\n",
            " [ 104    1   63  543   19   13    0]\n",
            " [   0  145    4   26  381    0    0]]\n",
            "\n",
            "Method: def-rf\n",
            "Accuracy: 0.66995\n",
            "Confusion Matrix:\n",
            "[[ 232    0    4  161  181   84    5]\n",
            " [   0 1562    0   49  342    0    3]\n",
            " [  11    0  585   34    4   19  102]\n",
            " [ 127    0  112  710  137   48   31]\n",
            " [  11   61   14   96 1647    3   37]\n",
            " [  60    0   17  222   37  403    4]\n",
            " [   4   62    2   41  420    0   27]]\n",
            "\n",
            "Method: def-dt\n",
            "Accuracy: 0.60252\n",
            "Confusion Matrix:\n",
            "[[ 229    5    7  144  175   79   28]\n",
            " [   0 1484    1  118  345    0    8]\n",
            " [  10   11  451   42   61   11  169]\n",
            " [ 133    2  119  555  177   95   84]\n",
            " [  10  138   46  111 1471    5   88]\n",
            " [  87    1   19  188   51  362   35]\n",
            " [   2   87    7   63  288   15   94]]\n",
            "\n",
            "Classifier opt-knn is not trained!\n",
            "\n",
            "Classifier opt-svm is not trained!\n",
            "\n",
            "Classifier opt-rf is not trained!\n",
            "\n",
            "Classifier opt-dt is not trained!\n",
            "\n",
            "Best Subset 1: [2, 5, 25, 30, 35, 40, 45]\n",
            "Best Subset 2: ['mean']\n",
            "Best Objective Value: 0.6744909869018285\n",
            "Cl test [0.6699520165996629, 'def-rf']\n",
            "\n",
            "Bayesian Optimization:\n",
            "L: [2, 5, 20, 25, 30], F: ['var'], accuracy: [0.6481649591492673, 'def-rf']\n",
            "L: [20, 30, 40, 48], F: ['var'], accuracy: [0.6105563480741797, 'def-rf']\n",
            "L: [2, 5, 20, 25, 30, 35], F: ['mean'], accuracy: [0.6901828556607444, 'def-rf']\n",
            "L: [35, 45, 48], F: ['var'], accuracy: [0.5589417714952665, 'def-rf']\n",
            "L: [2, 25, 30, 45, 48], F: ['mean', 'var'], accuracy: [0.6731941382440669, 'def-rf']\n",
            "L: [2, 5, 30, 40, 48], F: ['mean', 'var'], accuracy: [0.6761768901569187, 'def-rf']\n",
            "L: [5, 20, 25, 30, 35], F: ['var'], accuracy: [0.6252107379068863, 'def-rf']\n",
            "L: [20, 25, 30, 40, 45, 48], F: ['mean', 'var'], accuracy: [0.648683698612372, 'def-rf']\n",
            "L: [25, 30, 35, 48], F: [], accuracy: [0.6503696018674621, 'def-rf']\n",
            "L: [5, 20, 35, 45, 48], F: ['mean', 'var'], accuracy: [0.6591881727402412, 'def-rf']\n",
            "Method: def-knn\n",
            "Accuracy: 0.55985\n",
            "Confusion Matrix:\n",
            "[[ 235    3    6  160  163  100    0]\n",
            " [   1 1366   19  158  411    1    0]\n",
            " [  10    4  552   47   15   12  115]\n",
            " [ 144    3  138  601  155  101   23]\n",
            " [  26  275   32  181 1330    4   21]\n",
            " [ 154    1   12  327   37  211    1]\n",
            " [   0  202    6   40  285    1   22]]\n",
            "\n",
            "Method: def-svm\n",
            "Accuracy: 0.60485\n",
            "Confusion Matrix:\n",
            "[[ 221   12    9  280  145    0    0]\n",
            " [   0 1630    9   49  268    0    0]\n",
            " [   6    3  672   73    0    1    0]\n",
            " [  44    3  205  741  165    7    0]\n",
            " [  10  255   40  176 1387    1    0]\n",
            " [ 103    1   63  544   19   13    0]\n",
            " [   0  145    4   26  381    0    0]]\n",
            "\n",
            "Method: def-rf\n",
            "Accuracy: 0.68798\n",
            "Confusion Matrix:\n",
            "[[ 228    0    4  200  171   55    9]\n",
            " [   0 1724    0   33  197    0    2]\n",
            " [  10    1  577   43    7   11  106]\n",
            " [ 107    0  103  701  150   58   46]\n",
            " [   9   71   13   84 1658    1   33]\n",
            " [  63    0   18  220   37  402    3]\n",
            " [   2   89    4   41  405    0   15]]\n",
            "\n",
            "Method: def-dt\n",
            "Accuracy: 0.58643\n",
            "Confusion Matrix:\n",
            "[[ 172    3    7  250  157   59   19]\n",
            " [   0 1428    4   41  475    1    7]\n",
            " [  14   23  482   52   25   16  143]\n",
            " [ 146    6  123  523  182  111   74]\n",
            " [  14  150   25  107 1491   12   70]\n",
            " [  78    0   49  174   62  352   28]\n",
            " [   6  141    9   58  263    5   74]]\n",
            "\n",
            "Classifier opt-knn is not trained!\n",
            "\n",
            "Classifier opt-svm is not trained!\n",
            "\n",
            "Classifier opt-rf is not trained!\n",
            "\n",
            "Classifier opt-dt is not trained!\n",
            "\n",
            "Best Subset 1: [2, 5, 20, 25, 30, 35]\n",
            "Best Subset 2: ['mean']\n",
            "Best Objective Value: 0.6901828556607444\n",
            "Cl test [[0.6879782129425496, 'def-rf', {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}], [0.6048502139800286, 'def-svm', {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}], [0.5864349630398132, 'def-dt', {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}], [0.5598495655556996, 'def-knn', {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7ztQ2eBGjgs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}